{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Desktop/project_data_new/embedding_768_TCGA_COAD.csv')\n",
    "data.index = data['PatientID']\n",
    "# drop the last two columns\n",
    "data = data.drop(data.columns[-2:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Desktop/project_data_new/embedding_768_TCGA_COAD_90percent_sample.csv')\n",
    "data.index = data['PatientID']\n",
    "# drop the 'PatientID' column\n",
    "data = data.drop('PatientID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target = pd.read_csv('~/Desktop/project_data_new/target_768_avg_expanded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target.index = data_target['Unnamed: 0']\n",
    "data_target = data_target.drop(['Unnamed: 0'], axis = 1)\n",
    "# only keep the columns with category in the name\n",
    "data_target = data_target.loc[:, data_target.columns.str.contains('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.index.isin(data_target.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target = data_target[data_target.index.isin(data.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, accuracy_score\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Extract the feature values from data\n",
    "X = data.values\n",
    "# data_target only keep the index in data\n",
    "data_target = data_target[data_target.index.isin(data.index)]\n",
    "# Specify the single target variable\n",
    "target_col = \"category_stromal_34\"\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Set the path for the classification report file\n",
    "# report_file_path = f\"/home/qiuaodon/Desktop/CRC_image/Best_100_features_Randomforest_90percents/Classification_Report_100features_{target_col}.txt\"\n",
    "\n",
    "# Extract the target column for the current category from training/validation set\n",
    "Y = data_target[target_col].values\n",
    "\n",
    "# Select top 100 features using RFE\n",
    "rfe = RFE(rf, n_features_to_select=100)  # Choose top 100 features\n",
    "X_selected = rfe.fit_transform(X, Y)\n",
    "\n",
    "# Split the remaining training/validation set into train and validation\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_selected, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# Define the hyperparameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': randint(251, 253),\n",
    "    'max_depth': randint(33, 35),\n",
    "    'min_samples_split': randint(10, 12),\n",
    "    'min_samples_leaf': randint(1, 2),\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "{'max_depth': 34,\n",
    " 'max_features': 'sqrt',\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 11,\n",
    " 'n_estimators': 252}\n",
    "\n",
    "# Perform Randomized Search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=200, \n",
    "                                   cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model from Randomized Search\n",
    "best_rf = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Fit the model on the training data for evaluation\n",
    "best_rf.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_rf.predict(X_train)\n",
    "train_report = classification_report(Y_train, Y_train_pred)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "Y_val_pred = best_rf.predict(X_val)\n",
    "val_report = classification_report(Y_val, Y_val_pred, output_dict=True)\n",
    "\n",
    "\n",
    "# Calculate metrics for validation set\n",
    "precision = precision_score(Y_val, Y_val_pred, average='weighted')\n",
    "recall = recall_score(Y_val, Y_val_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_val, Y_val_pred)\n",
    "\n",
    "# Extract validation Class 1 metrics\n",
    "class_1_metrics = val_report.get('1', {\"precision\": None, \"recall\": None, \"f1-score\": None})\n",
    "\n",
    "\n",
    "\n",
    "# Append results for the target variable\n",
    "results.append({\n",
    "    \"Target Variable\": target_col,\n",
    "    \"Validation Precision\": precision,\n",
    "    \"Validation Recall\": recall,\n",
    "    \"Validation Accuracy\": accuracy,\n",
    "    \"Class 1 Precision (Validation)\": class_1_metrics[\"precision\"],\n",
    "    \"Class 1 Recall (Validation)\": class_1_metrics[\"recall\"],\n",
    "    \"Class 1 F1-Score (Validation)\": class_1_metrics[\"f1-score\"],\n",
    "    \"Best Hyperparameters\": best_params\n",
    "})\n",
    "\n",
    "# Save the results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 46,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 11,\n",
       " 'n_estimators': 204}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 34,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 11,\n",
       " 'n_estimators': 252}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
