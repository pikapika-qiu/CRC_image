{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint, uniform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Desktop/project_data_new/embedding_768_TCGA_COAD.csv')\n",
    "data.index = data['PatientID']\n",
    "# drop last 2 columns\n",
    "data = data.drop(data.columns[-2:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target = pd.read_csv('~/Desktop/project_data_new/target_768_avg_expanded.csv')\n",
    "data_target.index = data_target['Unnamed: 0']\n",
    "data_target = data_target.drop(['Unnamed: 0'], axis = 1)\n",
    "# only keep the columns with category in the name\n",
    "data_target = data_target.loc[:, data_target.columns.str.contains('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.index.isin(data_target.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_tnk_1</th>\n",
       "      <th>category_tnk_2</th>\n",
       "      <th>category_tnk_3</th>\n",
       "      <th>category_tnk_4</th>\n",
       "      <th>category_tnk_5</th>\n",
       "      <th>category_tnk_6</th>\n",
       "      <th>category_tnk_7</th>\n",
       "      <th>category_tnk_8</th>\n",
       "      <th>category_tnk_9</th>\n",
       "      <th>category_tnk_10</th>\n",
       "      <th>...</th>\n",
       "      <th>category_stromal_62</th>\n",
       "      <th>category_stromal_63</th>\n",
       "      <th>category_stromal_64</th>\n",
       "      <th>category_stromal_65</th>\n",
       "      <th>category_stromal_66</th>\n",
       "      <th>category_stromal_68</th>\n",
       "      <th>category_stromal_73</th>\n",
       "      <th>category_stromal_78</th>\n",
       "      <th>category_stromal_80</th>\n",
       "      <th>category_stromal_85</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-A6-6650</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A6-6142</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-5M-AAT4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A6-2676</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A6-6652</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-G4-6321</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-RU-A8FL</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-G4-6303</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-QG-A5Z1</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-G4-6588</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              category_tnk_1  category_tnk_2  category_tnk_3  category_tnk_4  \\\n",
       "Unnamed: 0                                                                     \n",
       "TCGA-A6-6650              -1              -1              -1              -1   \n",
       "TCGA-A6-6142               1               1               0               0   \n",
       "TCGA-5M-AAT4              -1              -1              -1               0   \n",
       "TCGA-A6-2676               1               1               1               0   \n",
       "TCGA-A6-6652              -1              -1              -1              -1   \n",
       "...                      ...             ...             ...             ...   \n",
       "TCGA-G4-6321               1               1               1              -1   \n",
       "TCGA-RU-A8FL              -1              -1              -1               1   \n",
       "TCGA-G4-6303              -1               0              -1              -1   \n",
       "TCGA-QG-A5Z1              -1               0              -1              -1   \n",
       "TCGA-G4-6588               0              -1               0               0   \n",
       "\n",
       "              category_tnk_5  category_tnk_6  category_tnk_7  category_tnk_8  \\\n",
       "Unnamed: 0                                                                     \n",
       "TCGA-A6-6650              -1              -1              -1              -1   \n",
       "TCGA-A6-6142               0               0               0               0   \n",
       "TCGA-5M-AAT4              -1              -1              -1              -1   \n",
       "TCGA-A6-2676               1               1               1               1   \n",
       "TCGA-A6-6652              -1              -1              -1              -1   \n",
       "...                      ...             ...             ...             ...   \n",
       "TCGA-G4-6321               1               1               1               1   \n",
       "TCGA-RU-A8FL              -1              -1              -1              -1   \n",
       "TCGA-G4-6303               0               0               0              -1   \n",
       "TCGA-QG-A5Z1              -1              -1              -1              -1   \n",
       "TCGA-G4-6588               0               0              -1               0   \n",
       "\n",
       "              category_tnk_9  category_tnk_10  ...  category_stromal_62  \\\n",
       "Unnamed: 0                                     ...                        \n",
       "TCGA-A6-6650               1               -1  ...                   -1   \n",
       "TCGA-A6-6142              -1                0  ...                    1   \n",
       "TCGA-5M-AAT4               1               -1  ...                   -1   \n",
       "TCGA-A6-2676               1                1  ...                    0   \n",
       "TCGA-A6-6652              -1               -1  ...                   -1   \n",
       "...                      ...              ...  ...                  ...   \n",
       "TCGA-G4-6321              -1                1  ...                    0   \n",
       "TCGA-RU-A8FL               1               -1  ...                   -1   \n",
       "TCGA-G4-6303              -1                1  ...                    1   \n",
       "TCGA-QG-A5Z1              -1                0  ...                    1   \n",
       "TCGA-G4-6588               1                0  ...                   -1   \n",
       "\n",
       "              category_stromal_63  category_stromal_64  category_stromal_65  \\\n",
       "Unnamed: 0                                                                    \n",
       "TCGA-A6-6650                   -1                   -1                   -1   \n",
       "TCGA-A6-6142                    1                    1                    1   \n",
       "TCGA-5M-AAT4                   -1                   -1                   -1   \n",
       "TCGA-A6-2676                   -1                    0                   -1   \n",
       "TCGA-A6-6652                   -1                   -1                   -1   \n",
       "...                           ...                  ...                  ...   \n",
       "TCGA-G4-6321                    0                   -1                    1   \n",
       "TCGA-RU-A8FL                   -1                   -1                   -1   \n",
       "TCGA-G4-6303                    1                    1                    0   \n",
       "TCGA-QG-A5Z1                    1                    0                    0   \n",
       "TCGA-G4-6588                   -1                   -1                   -1   \n",
       "\n",
       "              category_stromal_66  category_stromal_68  category_stromal_73  \\\n",
       "Unnamed: 0                                                                    \n",
       "TCGA-A6-6650                   -1                    1                   -1   \n",
       "TCGA-A6-6142                    1                   -1                    0   \n",
       "TCGA-5M-AAT4                   -1                    1                   -1   \n",
       "TCGA-A6-2676                    0                    1                    0   \n",
       "TCGA-A6-6652                   -1                   -1                   -1   \n",
       "...                           ...                  ...                  ...   \n",
       "TCGA-G4-6321                    1                   -1                    1   \n",
       "TCGA-RU-A8FL                   -1                    1                   -1   \n",
       "TCGA-G4-6303                    1                   -1                    0   \n",
       "TCGA-QG-A5Z1                    0                   -1                   -1   \n",
       "TCGA-G4-6588                   -1                    1                    0   \n",
       "\n",
       "              category_stromal_78  category_stromal_80  category_stromal_85  \n",
       "Unnamed: 0                                                                   \n",
       "TCGA-A6-6650                   -1                    1                    1  \n",
       "TCGA-A6-6142                    0                   -1                   -1  \n",
       "TCGA-5M-AAT4                   -1                    1                    1  \n",
       "TCGA-A6-2676                    1                    1                    1  \n",
       "TCGA-A6-6652                   -1                   -1                   -1  \n",
       "...                           ...                  ...                  ...  \n",
       "TCGA-G4-6321                    1                   -1                   -1  \n",
       "TCGA-RU-A8FL                   -1                    1                    1  \n",
       "TCGA-G4-6303                    0                   -1                   -1  \n",
       "TCGA-QG-A5Z1                   -1                   -1                   -1  \n",
       "TCGA-G4-6588                    0                    1                    1  \n",
       "\n",
       "[449 rows x 241 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Assuming X and Y_category_b_12 are already defined\n",
    "X = data.values\n",
    "Y_category_b_12 = data_target['category_b_12'].values\n",
    "label_encoder = LabelEncoder()\n",
    "Y_category_b_12 = label_encoder.fit_transform(Y_category_b_12)\n",
    "# Stratified split of the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_category_b_12, test_size=0.2, random_state=42, stratify=Y_category_b_12)\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', random_state=42)\n",
    "\n",
    "# Define the hyperparameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': randint(1000, 5000),\n",
    "    'learning_rate': uniform(0.01, 0.1),     # 0.01 to 0.11\n",
    "    'max_depth': randint(3, 10),\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'subsample': uniform(0.5, 0.5),          # 0.5 to 1.0\n",
    "    'colsample_bytree': uniform(0.5, 0.5),   # 0.5 to 1.0\n",
    "    'gamma': uniform(0, 5),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(1, 5),             # Start from 1 to avoid zero regularization\n",
    "}\n",
    "\n",
    "# Perform Randomized Search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=xgb_clf, param_distributions=param_dist, n_iter=50, \n",
    "                                   cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model from Randomized Search\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters from Randomized Search:\", random_search.best_params_)\n",
    "\n",
    "# Cross-validation on the training set with the best model\n",
    "cv_scores = cross_val_score(best_xgb, X_train, Y_train, cv=5, scoring='f1_weighted')\n",
    "print(\"Cross-validation F1 scores on training set:\", cv_scores)\n",
    "print(\"Average cross-validation F1 score on training set:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the training data for the final evaluation on test and train sets\n",
    "best_xgb.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_xgb.predict(X_train)\n",
    "print(\"Classification Report for category_b_12 with 100 features (Train Set):\")\n",
    "print(classification_report(Y_train, Y_train_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_test_pred = best_xgb.predict(X_test)\n",
    "print(\"Classification Report for category_b_12 with 100 features (Test Set):\")\n",
    "print(classification_report(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Hyperparameters from Randomized Search: {'colsample_bytree': 0.7323592099410596, 'gamma': 0.03177917514301182, 'learning_rate': 0.10329469651469865, 'max_depth': 10, 'min_child_weight': 5, 'n_estimators': 198, 'subsample': 0.8365191150830908}\n",
      "Cross-validation F1 scores on training set: [0.50189167 0.41718132 0.49907191 0.39585521 0.52024264]\n",
      "Average cross-validation F1 score on training set: 0.466848549262388\n",
      "Classification Report for category_b_12 with 100 features (Train Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       120\n",
      "           1       1.00      1.00      1.00       119\n",
      "           2       1.00      1.00      1.00       120\n",
      "\n",
      "    accuracy                           1.00       359\n",
      "   macro avg       1.00      1.00      1.00       359\n",
      "weighted avg       1.00      1.00      1.00       359\n",
      "\n",
      "Classification Report for category_b_12 with 100 features (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.47      0.47        30\n",
      "           1       0.45      0.43      0.44        30\n",
      "           2       0.55      0.57      0.56        30\n",
      "\n",
      "    accuracy                           0.49        90\n",
      "   macro avg       0.49      0.49      0.49        90\n",
      "weighted avg       0.49      0.49      0.49        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Assuming X and Y_category_b_12 are already defined\n",
    "X = data.values\n",
    "Y_category_b_12 = data_target['category_b_12'].values\n",
    "label_encoder = LabelEncoder()\n",
    "Y_category_b_12 = label_encoder.fit_transform(Y_category_b_12)\n",
    "# Stratified split of the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_category_b_12, test_size=0.2, random_state=42, stratify=Y_category_b_12)\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', random_state=42)\n",
    "\n",
    "# Define the hyperparameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(3, 15),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'gamma': uniform(0, 0.5)\n",
    "}\n",
    "\n",
    "# Perform Randomized Search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=xgb_clf, param_distributions=param_dist, n_iter=50, \n",
    "                                   cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model from Randomized Search\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters from Randomized Search:\", random_search.best_params_)\n",
    "\n",
    "# Cross-validation on the training set with the best model\n",
    "cv_scores = cross_val_score(best_xgb, X_train, Y_train, cv=5, scoring='f1_weighted')\n",
    "print(\"Cross-validation F1 scores on training set:\", cv_scores)\n",
    "print(\"Average cross-validation F1 score on training set:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the training data for the final evaluation on test and train sets\n",
    "best_xgb.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_xgb.predict(X_train)\n",
    "print(\"Classification Report for category_b_12 with 100 features (Train Set):\")\n",
    "print(classification_report(Y_train, Y_train_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_test_pred = best_xgb.predict(X_test)\n",
    "print(\"Classification Report for category_b_12 with 100 features (Test Set):\")\n",
    "print(classification_report(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Hyperparameters from Randomized Search: {'colsample_bytree': 0.5257393756249946, 'gamma': 1.3932323211830573, 'learning_rate': 0.09174392973699882, 'max_depth': 4, 'min_child_weight': 6, 'n_estimators': 552, 'reg_alpha': 0.489452760277563, 'reg_lambda': 9.856504541106007, 'subsample': 0.6210276357557503}\n",
      "Cross-validation F1 scores on training set: [0.48863636 0.38843055 0.47293886 0.36705517 0.54819698]\n",
      "Average cross-validation F1 score on training set: 0.45305158492273556\n",
      "Classification Report for category_b_12 with 100 features (Train Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       120\n",
      "           1       0.98      0.97      0.98       119\n",
      "           2       0.98      0.98      0.98       120\n",
      "\n",
      "    accuracy                           0.98       359\n",
      "   macro avg       0.98      0.98      0.98       359\n",
      "weighted avg       0.98      0.98      0.98       359\n",
      "\n",
      "Classification Report for category_b_12 with 100 features (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.50      0.52        30\n",
      "           1       0.45      0.43      0.44        30\n",
      "           2       0.58      0.63      0.60        30\n",
      "\n",
      "    accuracy                           0.52        90\n",
      "   macro avg       0.52      0.52      0.52        90\n",
      "weighted avg       0.52      0.52      0.52        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Assuming X and Y_category_b_12 are already defined\n",
    "X = data.values\n",
    "Y_category_b_12 = data_target['category_b_12'].values\n",
    "label_encoder = LabelEncoder()\n",
    "Y_category_b_12 = label_encoder.fit_transform(Y_category_b_12)\n",
    "# Stratified split of the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_category_b_12, test_size=0.2, random_state=42, stratify=Y_category_b_12)\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(500, 1000),  # Increased upper bound\n",
    "    'max_depth': randint(2, 8),          # Reduced depth\n",
    "    'learning_rate': uniform(0.01, 0.09),# Lower learning rates\n",
    "    'subsample': uniform(0.5, 0.5),      # Range from 0.5 to 1.0\n",
    "    'colsample_bytree': uniform(0.5, 0.5),\n",
    "    'min_child_weight': randint(5, 15),  # Increased minimum\n",
    "    'gamma': uniform(0, 5),              # Expanded range\n",
    "    'reg_alpha': uniform(0, 1),          # Added L1 regularization\n",
    "    'reg_lambda': uniform(0, 10),        # Added L2 regularization\n",
    "}\n",
    "\n",
    "# Perform Randomized Search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=xgb_clf, param_distributions=param_dist, n_iter=50, \n",
    "                                   cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model from Randomized Search\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters from Randomized Search:\", random_search.best_params_)\n",
    "\n",
    "# Cross-validation on the training set with the best model\n",
    "cv_scores = cross_val_score(best_xgb, X_train, Y_train, cv=5, scoring='f1_weighted')\n",
    "print(\"Cross-validation F1 scores on training set:\", cv_scores)\n",
    "print(\"Average cross-validation F1 score on training set:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the training data for the final evaluation on test and train sets\n",
    "best_xgb.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_xgb.predict(X_train)\n",
    "print(\"Classification Report for category_b_12 with 100 features (Train Set):\")\n",
    "print(classification_report(Y_train, Y_train_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_test_pred = best_xgb.predict(X_test)\n",
    "print(\"Classification Report for category_b_12 with 100 features (Test Set):\")\n",
    "print(classification_report(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Hyperparameters from Randomized Search: {'colsample_bytree': 0.5866471600354228, 'gamma': 0.7821852133554302, 'learning_rate': 0.03252186083481358, 'max_depth': 7, 'min_child_weight': 10, 'n_estimators': 547, 'reg_alpha': 0.18286599710730733, 'reg_lambda': 9.346139973397097, 'subsample': 0.8191352969216752}\n",
      "Cross-validation F1 scores on training set: [0.56608155 0.44555012 0.51604938 0.51551307 0.51535495]\n",
      "Average cross-validation F1 score on training set: 0.5117098133827519\n",
      "Classification Report for category_b_12 with 100 selected features (Train Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       120\n",
      "           1       0.98      0.97      0.98       119\n",
      "           2       0.98      0.98      0.98       120\n",
      "\n",
      "    accuracy                           0.98       359\n",
      "   macro avg       0.98      0.98      0.98       359\n",
      "weighted avg       0.98      0.98      0.98       359\n",
      "\n",
      "Classification Report for category_b_12 with 100 selected features (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.40      0.39        30\n",
      "           1       0.48      0.47      0.47        30\n",
      "           2       0.69      0.67      0.68        30\n",
      "\n",
      "    accuracy                           0.51        90\n",
      "   macro avg       0.52      0.51      0.51        90\n",
      "weighted avg       0.52      0.51      0.51        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Assuming X and Y_category_b_12 are already defined\n",
    "X = data.values\n",
    "Y_category_b_12 = data_target['category_b_12'].values\n",
    "label_encoder = LabelEncoder()\n",
    "Y_category_b_12 = label_encoder.fit_transform(Y_category_b_12)\n",
    "\n",
    "# Stratified split of the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_category_b_12, test_size=0.2, random_state=42, stratify=Y_category_b_12)\n",
    "\n",
    "# Step 1: Initialize XGBoost Classifier and RFE\n",
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', random_state=42)\n",
    "rfe = RFE(estimator=xgb_clf, n_features_to_select=100)  # Choose top 100 features\n",
    "\n",
    "# Fit RFE to select top 100 features\n",
    "X_train_rfe = rfe.fit_transform(X_train, Y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(500, 1000),  # Increased upper bound\n",
    "    'max_depth': randint(2, 8),          # Reduced depth\n",
    "    'learning_rate': uniform(0.01, 0.09),# Lower learning rates\n",
    "    'subsample': uniform(0.5, 0.5),      # Range from 0.5 to 1.0\n",
    "    'colsample_bytree': uniform(0.5, 0.5),\n",
    "    'min_child_weight': randint(5, 15),  # Increased minimum\n",
    "    'gamma': uniform(0, 5),              # Expanded range\n",
    "    'reg_alpha': uniform(0, 1),          # Added L1 regularization\n",
    "    'reg_lambda': uniform(0, 10),        # Added L2 regularization\n",
    "}\n",
    "\n",
    "# Perform Randomized Search with cross-validation on the selected features\n",
    "random_search = RandomizedSearchCV(estimator=xgb_clf, param_distributions=param_dist, n_iter=50, \n",
    "                                   cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search.fit(X_train_rfe, Y_train)\n",
    "\n",
    "# Get the best model from Randomized Search\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters from Randomized Search:\", random_search.best_params_)\n",
    "\n",
    "# Cross-validation on the training set with the best model\n",
    "cv_scores = cross_val_score(best_xgb, X_train_rfe, Y_train, cv=5, scoring='f1_weighted')\n",
    "print(\"Cross-validation F1 scores on training set:\", cv_scores)\n",
    "print(\"Average cross-validation F1 score on training set:\", np.mean(cv_scores))\n",
    "\n",
    "# Step 3: Fit the model on the training data for the final evaluation on test and train sets\n",
    "best_xgb.fit(X_train_rfe, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_xgb.predict(X_train_rfe)\n",
    "print(\"Classification Report for category_b_12 with 100 selected features (Train Set):\")\n",
    "print(classification_report(Y_train, Y_train_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_test_pred = best_xgb.predict(X_test_rfe)\n",
    "print(\"Classification Report for category_b_12 with 100 selected features (Test Set):\")\n",
    "print(classification_report(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Assuming 'data' and 'data_target' are your feature matrix and target DataFrame respectively\n",
    "# X contains feature values\n",
    "X = data.values\n",
    "\n",
    "# Set the chunk size (number of target variables per part)\n",
    "chunk_size = 40\n",
    "\n",
    "# Loop through target columns in chunks\n",
    "for chunk_start in range(0, 241, chunk_size):\n",
    "    # Get the current chunk of target columns\n",
    "    chunk_end = min(chunk_start + chunk_size, 241)\n",
    "    target_chunk = data_target.columns[chunk_start:chunk_end]\n",
    "    \n",
    "    # Initialize list to store results for the current chunk\n",
    "    chunk_results = []\n",
    "\n",
    "    # Open a file to write classification reports for the current chunk\n",
    "    report_file_path = f\"/home/qiuaodon/Desktop/CRC_image/XGboost_results/Classification_Reports_100features_part_{chunk_start}_{chunk_end}.txt\"\n",
    "    with open(report_file_path, \"w\") as report_file:\n",
    "        # Iterate over each target column in the chunk\n",
    "        for target_col in target_chunk:\n",
    "            # Extract the target column for the current category\n",
    "            Y = data_target[target_col].values\n",
    "\n",
    "            # Encode labels if they are not numerical\n",
    "            label_encoder = LabelEncoder()\n",
    "            Y_encoded = label_encoder.fit_transform(Y)\n",
    "\n",
    "            # Initialize the XGBoost Classifier\n",
    "            xgb_clf = xgb.XGBClassifier(\n",
    "                objective='multi:softmax', \n",
    "                random_state=42, \n",
    "                use_label_encoder=False,\n",
    "                eval_metric='mlogloss'\n",
    "            )\n",
    "\n",
    "            # Select top 100 features using RFE\n",
    "            rfe = RFE(estimator=xgb_clf, n_features_to_select=100)\n",
    "            X_selected = rfe.fit_transform(X, Y_encoded)\n",
    "            \n",
    "            # Split the data into training and testing sets with stratification\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "                X_selected, Y_encoded, test_size=0.2, random_state=42, stratify=Y_encoded\n",
    "            )\n",
    "\n",
    "            # Define the hyperparameter distribution for XGBoost\n",
    "            param_dist = {\n",
    "                'n_estimators': randint(500, 1000),  # Increased upper bound\n",
    "                'max_depth': randint(2, 8),          # Reduced depth\n",
    "                'learning_rate': uniform(0.01, 0.09),# Lower learning rates\n",
    "                'subsample': uniform(0.5, 0.5),      # Range from 0.5 to 1.0\n",
    "                'colsample_bytree': uniform(0.5, 0.5),\n",
    "                'min_child_weight': randint(5, 15),  # Increased minimum\n",
    "                'gamma': uniform(0, 5),              # Expanded range\n",
    "                'reg_alpha': uniform(0, 1),          # Added L1 regularization\n",
    "                'reg_lambda': uniform(0, 10),        # Added L2 regularization\n",
    "            }\n",
    "\n",
    "            # Perform Randomized Search with cross-validation\n",
    "            random_search = RandomizedSearchCV(\n",
    "                estimator=xgb_clf,\n",
    "                param_distributions=param_dist,\n",
    "                n_iter=50, \n",
    "                cv=5, \n",
    "                scoring='f1_weighted', \n",
    "                n_jobs=-1, \n",
    "                verbose=1, \n",
    "                random_state=42\n",
    "            )\n",
    "            random_search.fit(X_train, Y_train)\n",
    "\n",
    "            # Get the best model from Randomized Search\n",
    "            best_xgb = random_search.best_estimator_\n",
    "            best_params = random_search.best_params_\n",
    "\n",
    "            # Fit the best model on the training data\n",
    "            best_xgb.fit(X_train, Y_train)\n",
    "\n",
    "            # Evaluate on the training set\n",
    "            Y_train_pred = best_xgb.predict(X_train)\n",
    "            train_report = classification_report(Y_train, Y_train_pred)\n",
    "\n",
    "            # Evaluate on the test set\n",
    "            Y_test_pred = best_xgb.predict(X_test)\n",
    "            test_report_dict = classification_report(Y_test, Y_test_pred, output_dict=True)\n",
    "            test_report = classification_report(Y_test, Y_test_pred)\n",
    "\n",
    "            # Write classification reports to the file\n",
    "            report_file.write(f\"Classification Report for {target_col} (Train Set):\\n\")\n",
    "            report_file.write(train_report)\n",
    "            report_file.write(\"\\n\")\n",
    "            report_file.write(f\"Classification Report for {target_col} (Test Set):\\n\")\n",
    "            report_file.write(test_report)\n",
    "            report_file.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\")\n",
    "\n",
    "            # Calculate and store precision, recall, and accuracy\n",
    "            precision = precision_score(Y_test, Y_test_pred, average='weighted')\n",
    "            recall = recall_score(Y_test, Y_test_pred, average='weighted')\n",
    "            accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "\n",
    "            # Extract precision, recall, and f1-score specifically for class '1' (if it exists)\n",
    "            class_labels = label_encoder.classes_\n",
    "            class_indices = label_encoder.transform(class_labels)\n",
    "            class_1_index = np.where(class_indices == 1)[0]\n",
    "\n",
    "            if class_1_index.size > 0:\n",
    "                class_1_label = str(class_indices[class_1_index[0]])\n",
    "                class_1_metrics = test_report_dict.get(class_1_label, {\"precision\": None, \"recall\": None, \"f1-score\": None})\n",
    "            else:\n",
    "                class_1_metrics = {\"precision\": None, \"recall\": None, \"f1-score\": None}\n",
    "\n",
    "            chunk_results.append({\n",
    "                \"Target Variable\": target_col,\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"Accuracy\": accuracy,\n",
    "                \"Class 1 Precision\": class_1_metrics[\"precision\"],\n",
    "                \"Class 1 Recall\": class_1_metrics[\"recall\"],\n",
    "                \"Class 1 F1-Score\": class_1_metrics[\"f1-score\"],\n",
    "                \"Best Hyperparameters\": best_params\n",
    "            })\n",
    "    \n",
    "    # Save the results for the current chunk to an Excel file\n",
    "    results_df = pd.DataFrame(chunk_results)\n",
    "    results_df.to_excel(\n",
    "        f\"/home/qiuaodon/Desktop/CRC_image/XGboost_results/Precision_Recall_Accuracy_100features_part_{chunk_start}_{chunk_end}.xlsx\",\n",
    "        index=False\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
