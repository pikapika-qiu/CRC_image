{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "rf = RandomForestClassifier()\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(407, 768) (449, 241)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('~/Desktop/project_data_new/embedding_768_TCGA_COAD_90percent_sample.csv', index_col='PatientID')\n",
    "data_target = pd.read_csv('~/Desktop/project_data_new/target_768_avg_expanded.csv', index_col=0)\n",
    "# only keep the columns with category in the name\n",
    "data_target = data_target.loc[:, data_target.columns.str.contains('category')]\n",
    "data = data[data.index.isin(data_target.index)]\n",
    "print(data.shape, data_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 768)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('~/Desktop/project_data_new/embedding_768_TCGA_COAD_10percent_sample.csv', index_col='PatientID')\n",
    "data_test = data_test[data_test.index.isin(data_target.index)]\n",
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407, 241)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Align the targets for training and unseen test sets\n",
    "data_target_train = data_target.loc[data.index]\n",
    "data_target_unseen = data_target.loc[data_test.index]\n",
    "data_target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, accuracy_score\n",
    "from scipy.stats import randint\n",
    "import os\n",
    "\n",
    "# ===========================\n",
    "# Configuration and Data Setup\n",
    "# ===========================\n",
    "# data: 407 x 768 features (90% of samples)\n",
    "# data_target_train: 407 x 241 target variables\n",
    "# data_test: Matching features for the test set\n",
    "# data_target_unseen: Matching targets for the test set\n",
    "\n",
    "X = data.values  # All 407 samples with 768 features\n",
    "X_test = data_test.values\n",
    "\n",
    "targets = data_target_train.columns\n",
    "n_targets = len(targets) \n",
    "chunk_size = 40 # process 40 targets at a time (to avoid memory issues)\n",
    "\n",
    "# Directory for saving outputs\n",
    "output_dir = \"/home/qiuaodon/Desktop/CRC_image/Best_100_features_Randomforest_90percents_version2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ===========================\n",
    "# Parameter Distributions for Hyperparameter Tuning\n",
    "# ===========================\n",
    "param_dist = {\n",
    "    'clf__n_estimators': randint(100, 200),\n",
    "    'clf__max_depth': randint(20, 40),\n",
    "    'clf__min_samples_split': randint(10, 20),\n",
    "    'clf__min_samples_leaf': randint(1, 5),\n",
    "    'clf__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# ===========================\n",
    "# Pipeline Setup\n",
    "# ===========================\n",
    "# The pipeline first performs RFE (for feature selection) using an internal RF model,\n",
    "# then trains a Random Forest Classifier with the selected features.\n",
    "# 'rfe__n_features_to_select': Fixed at 100 for top feature selection.\n",
    "# The base estimator inside RFE is a simple RF with fixed parameters, \n",
    "# since RFE is done as part of the pipeline and will be repeated during hyperparameter tuning.\n",
    "base_rf_for_rfe = RandomForestClassifier(random_state=42)\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFE(estimator=base_rf_for_rfe, n_features_to_select=100, step=1)),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# ===========================\n",
    "# Main Loop over Target Variables in Chunks\n",
    "# ===========================\n",
    "for chunk_start in range(0, n_targets, chunk_size):\n",
    "    chunk_end = min(chunk_start + chunk_size, n_targets)\n",
    "    target_chunk = targets[chunk_start:chunk_end]\n",
    "\n",
    "    # Prepare results storage\n",
    "    chunk_results = []\n",
    "\n",
    "    # Classification reports file for this chunk\n",
    "    report_file_path = os.path.join(\n",
    "        output_dir, \n",
    "        f\"Classification_Reports_top100_features_part_{chunk_start}_{chunk_end}.txt\"\n",
    "    )\n",
    "\n",
    "    with open(report_file_path, \"w\") as report_file:\n",
    "        for target_col in target_chunk:\n",
    "            # Extract the target variable for training/validation\n",
    "            Y = data_target_train[target_col].values\n",
    "\n",
    "            # Split into training and validation\n",
    "            X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "                X, Y, test_size=0.2, random_state=42, stratify=Y\n",
    "            )\n",
    "\n",
    "            # Hyperparameter tuning using RandomizedSearchCV\n",
    "            random_search = RandomizedSearchCV(\n",
    "                estimator=pipeline,\n",
    "                param_distributions=param_dist,\n",
    "                n_iter=60,\n",
    "                cv=5,\n",
    "                scoring='f1_weighted',\n",
    "                n_jobs=-1,\n",
    "                verbose=1,\n",
    "                random_state=42,\n",
    "                refit=True\n",
    "            )\n",
    "            random_search.fit(X_train, Y_train)\n",
    "\n",
    "            # Best model after hyperparameter search\n",
    "            best_model = random_search.best_estimator_\n",
    "            best_params = random_search.best_params_\n",
    "\n",
    "            # Evaluate on Training Set\n",
    "            Y_train_pred = best_model.predict(X_train)\n",
    "            train_report_str = classification_report(Y_train, Y_train_pred)\n",
    "\n",
    "            # Evaluate on Validation Set\n",
    "            Y_val_pred = best_model.predict(X_val)\n",
    "            val_report = classification_report(Y_val, Y_val_pred, output_dict=True)\n",
    "            val_report_str = classification_report(Y_val, Y_val_pred)\n",
    "\n",
    "            # Evaluate on Test Set (Unseen Data)\n",
    "            # Transform test data using the pipeline (it will apply the same RFE)\n",
    "            Y_test = data_target_unseen[target_col].values\n",
    "            Y_test_pred = best_model.predict(X_test)\n",
    "            test_report = classification_report(Y_test, Y_test_pred, output_dict=True)\n",
    "            test_report_str = classification_report(Y_test, Y_test_pred)\n",
    "\n",
    "            # Write reports to the file\n",
    "            report_file.write(f\"Target Variable: {target_col}\\n\")\n",
    "            report_file.write(\"=== Training Set Report ===\\n\")\n",
    "            report_file.write(train_report_str + \"\\n\\n\")\n",
    "            report_file.write(\"=== Validation Set Report ===\\n\")\n",
    "            report_file.write(val_report_str + \"\\n\\n\")\n",
    "            report_file.write(\"=== Test Set Report ===\\n\")\n",
    "            report_file.write(test_report_str + \"\\n\")\n",
    "            report_file.write(\"=\"*80 + \"\\n\\n\")\n",
    "\n",
    "            # Compute metrics for Validation Set\n",
    "            val_precision = precision_score(Y_val, Y_val_pred, average='weighted')\n",
    "            val_recall = recall_score(Y_val, Y_val_pred, average='weighted')\n",
    "            val_accuracy = accuracy_score(Y_val, Y_val_pred)\n",
    "\n",
    "            # Extract Class 1 metrics from Validation (if class '1' exists)\n",
    "            class_1_val_metrics = val_report.get('1', {\"precision\": None, \"recall\": None, \"f1-score\": None})\n",
    "\n",
    "            # Compute metrics for Test Set\n",
    "            test_precision = precision_score(Y_test, Y_test_pred, average='weighted')\n",
    "            test_recall = recall_score(Y_test, Y_test_pred, average='weighted')\n",
    "            test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "\n",
    "            # Extract Class 1 metrics from Test (if class '1' exists)\n",
    "            class_1_test_metrics = test_report.get('1', {\"precision\": None, \"recall\": None, \"f1-score\": None})\n",
    "\n",
    "            # Append metrics to chunk_results\n",
    "            chunk_results.append({\n",
    "                \"Target Variable\": target_col,\n",
    "                \"Validation Precision\": val_precision,\n",
    "                \"Validation Recall\": val_recall,\n",
    "                \"Validation Accuracy\": val_accuracy,\n",
    "                \"Class 1 Precision (Validation)\": class_1_val_metrics[\"precision\"],\n",
    "                \"Class 1 Recall (Validation)\": class_1_val_metrics[\"recall\"],\n",
    "                \"Class 1 F1-Score (Validation)\": class_1_val_metrics[\"f1-score\"],\n",
    "                \"Test Precision\": test_precision,\n",
    "                \"Test Recall\": test_recall,\n",
    "                \"Test Accuracy\": test_accuracy,\n",
    "                \"Class 1 Precision (Test)\": class_1_test_metrics[\"precision\"],\n",
    "                \"Class 1 Recall (Test)\": class_1_test_metrics[\"recall\"],\n",
    "                \"Class 1 F1-Score (Test)\": class_1_test_metrics[\"f1-score\"],\n",
    "                \"Best Hyperparameters\": best_params\n",
    "            })\n",
    "\n",
    "    # Save the metrics for the chunk to an Excel file\n",
    "    results_df = pd.DataFrame(chunk_results)\n",
    "    results_file_path = os.path.join(\n",
    "        output_dir,\n",
    "        f\"Metrics_top100_features_part_{chunk_start}_{chunk_end}.xlsx\"\n",
    "    )\n",
    "    results_df.to_excel(results_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Variable</th>\n",
       "      <th>Validation Precision</th>\n",
       "      <th>Validation Recall</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Class 1 Precision (Validation)</th>\n",
       "      <th>Class 1 Recall (Validation)</th>\n",
       "      <th>Class 1 F1-Score (Validation)</th>\n",
       "      <th>Unseen Test Precision</th>\n",
       "      <th>Unseen Test Recall</th>\n",
       "      <th>Unseen Test Accuracy</th>\n",
       "      <th>Class 1 Precision (Unseen Test)</th>\n",
       "      <th>Class 1 Recall (Unseen Test)</th>\n",
       "      <th>Class 1 F1-Score (Unseen Test)</th>\n",
       "      <th>Best Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category_tnk_1</td>\n",
       "      <td>0.476098</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.371849</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>{'max_depth': 25, 'max_features': 'log2', 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category_tnk_2</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.543515</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>{'max_depth': 23, 'max_features': 'sqrt', 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category_tnk_3</td>\n",
       "      <td>0.483284</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.180934</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>{'max_depth': 37, 'max_features': 'log2', 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category_tnk_4</td>\n",
       "      <td>0.560694</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.588409</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>{'max_depth': 28, 'max_features': 'sqrt', 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category_tnk_5</td>\n",
       "      <td>0.546459</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.353672</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>{'max_depth': 36, 'max_features': 'sqrt', 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>category_stromal_10</td>\n",
       "      <td>0.456924</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.480866</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>{'max_depth': 30, 'max_features': 'log2', 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>category_stromal_11</td>\n",
       "      <td>0.501768</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.367565</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>{'max_depth': 39, 'max_features': 'sqrt', 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>category_stromal_12</td>\n",
       "      <td>0.426071</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.379085</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'max_depth': 31, 'max_features': 'log2', 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>category_stromal_13</td>\n",
       "      <td>0.565932</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.391484</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>{'max_depth': 22, 'max_features': 'sqrt', 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>category_stromal_14</td>\n",
       "      <td>0.428033</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.529832</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>{'max_depth': 35, 'max_features': 'sqrt', 'min...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target Variable  Validation Precision  Validation Recall  \\\n",
       "0         category_tnk_1              0.476098           0.487805   \n",
       "1         category_tnk_2              0.514563           0.512195   \n",
       "2         category_tnk_3              0.483284           0.487805   \n",
       "3         category_tnk_4              0.560694           0.548780   \n",
       "4         category_tnk_5              0.546459           0.548780   \n",
       "..                   ...                   ...                ...   \n",
       "236  category_stromal_10              0.456924           0.451220   \n",
       "237  category_stromal_11              0.501768           0.500000   \n",
       "238  category_stromal_12              0.426071           0.426829   \n",
       "239  category_stromal_13              0.565932           0.560976   \n",
       "240  category_stromal_14              0.428033           0.426829   \n",
       "\n",
       "     Validation Accuracy  Class 1 Precision (Validation)  \\\n",
       "0               0.487805                        0.535714   \n",
       "1               0.512195                        0.483871   \n",
       "2               0.487805                        0.448276   \n",
       "3               0.548780                        0.650000   \n",
       "4               0.548780                        0.560000   \n",
       "..                   ...                             ...   \n",
       "236             0.451220                        0.451613   \n",
       "237             0.500000                        0.523810   \n",
       "238             0.426829                        0.379310   \n",
       "239             0.560976                        0.636364   \n",
       "240             0.426829                        0.400000   \n",
       "\n",
       "     Class 1 Recall (Validation)  Class 1 F1-Score (Validation)  \\\n",
       "0                       0.555556                       0.545455   \n",
       "1                       0.555556                       0.517241   \n",
       "2                       0.464286                       0.456140   \n",
       "3                       0.500000                       0.565217   \n",
       "4                       0.518519                       0.538462   \n",
       "..                           ...                            ...   \n",
       "236                     0.500000                       0.474576   \n",
       "237                     0.407407                       0.458333   \n",
       "238                     0.407407                       0.392857   \n",
       "239                     0.500000                       0.560000   \n",
       "240                     0.370370                       0.384615   \n",
       "\n",
       "     Unseen Test Precision  Unseen Test Recall  Unseen Test Accuracy  \\\n",
       "0                 0.371849            0.357143              0.357143   \n",
       "1                 0.543515            0.404762              0.404762   \n",
       "2                 0.180934            0.166667              0.166667   \n",
       "3                 0.588409            0.547619              0.547619   \n",
       "4                 0.353672            0.309524              0.309524   \n",
       "..                     ...                 ...                   ...   \n",
       "236               0.480866            0.428571              0.428571   \n",
       "237               0.367565            0.333333              0.333333   \n",
       "238               0.379085            0.404762              0.404762   \n",
       "239               0.391484            0.357143              0.357143   \n",
       "240               0.529832            0.523810              0.523810   \n",
       "\n",
       "     Class 1 Precision (Unseen Test)  Class 1 Recall (Unseen Test)  \\\n",
       "0                           0.294118                      0.357143   \n",
       "1                           0.375000                      0.400000   \n",
       "2                           0.125000                      0.181818   \n",
       "3                           0.733333                      0.523810   \n",
       "4                           0.266667                      0.285714   \n",
       "..                               ...                           ...   \n",
       "236                         0.315789                      0.600000   \n",
       "237                         0.363636                      0.266667   \n",
       "238                         0.500000                      0.500000   \n",
       "239                         0.250000                      0.363636   \n",
       "240                         0.647059                      0.687500   \n",
       "\n",
       "     Class 1 F1-Score (Unseen Test)  \\\n",
       "0                          0.322581   \n",
       "1                          0.387097   \n",
       "2                          0.148148   \n",
       "3                          0.611111   \n",
       "4                          0.275862   \n",
       "..                              ...   \n",
       "236                        0.413793   \n",
       "237                        0.307692   \n",
       "238                        0.500000   \n",
       "239                        0.296296   \n",
       "240                        0.666667   \n",
       "\n",
       "                                  Best Hyperparameters  \n",
       "0    {'max_depth': 25, 'max_features': 'log2', 'min...  \n",
       "1    {'max_depth': 23, 'max_features': 'sqrt', 'min...  \n",
       "2    {'max_depth': 37, 'max_features': 'log2', 'min...  \n",
       "3    {'max_depth': 28, 'max_features': 'sqrt', 'min...  \n",
       "4    {'max_depth': 36, 'max_features': 'sqrt', 'min...  \n",
       "..                                                 ...  \n",
       "236  {'max_depth': 30, 'max_features': 'log2', 'min...  \n",
       "237  {'max_depth': 39, 'max_features': 'sqrt', 'min...  \n",
       "238  {'max_depth': 31, 'max_features': 'log2', 'min...  \n",
       "239  {'max_depth': 22, 'max_features': 'sqrt', 'min...  \n",
       "240  {'max_depth': 35, 'max_features': 'sqrt', 'min...  \n",
       "\n",
       "[241 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Specify the directory where your files are located\n",
    "file_path_pattern = '/home/qiuaodon/Desktop/CRC_image/Best_100_features_Randomforest_90percents_version2/Precision_Recall_Accuracy_100features_part_*.xlsx'\n",
    "\n",
    "# Use glob to find all matching files\n",
    "all_files = glob.glob(file_path_pattern)\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Loop through each file and append its DataFrame to the list\n",
    "for file in all_files:\n",
    "    df = pd.read_excel(file)\n",
    "    data_frames.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new Excel file\n",
    "combined_df.to_excel('/home/qiuaodon/Desktop/CRC_image/Best_100_features_Randomforest_90percents_version2/top_100features_Randomforest_241_targets_90train.xlsx', index=False)\n",
    "combined_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
