{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint, uniform\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Desktop/project_data_new/embedding_768_TCGA_COAD_90percent_sample.csv')\n",
    "data.index = data['PatientID']\n",
    "# drop the 'PatientID' column\n",
    "data = data.drop('PatientID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target = pd.read_csv('~/Desktop/project_data_new/target_768_avg_expanded.csv')\n",
    "data_target.index = data_target['Unnamed: 0']\n",
    "data_target = data_target.drop(['Unnamed: 0'], axis = 1)\n",
    "# only keep the columns with category in the name\n",
    "data_target = data_target.loc[:, data_target.columns.str.contains('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('~/Desktop/project_data_new/embedding_768_TCGA_COAD_10percent_sample.csv')\n",
    "data_test.index = data_test['PatientID']\n",
    "# drop the 'PatientID' column\n",
    "data_test = data_test.drop('PatientID', axis=1)\n",
    "data_test = data_test[data_test.index.isin(data_target.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data.index.isin(data_target.index)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407, 241)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Align the targets for training and unseen test sets\n",
    "data_target_train = data_target.loc[data.index]\n",
    "data_target_unseen = data_target.loc[data_test.index]\n",
    "data_target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', random_state=42)\n",
    "\n",
    "# Extract the feature values from data\n",
    "X = data.values\n",
    "X_test_unseen = data_test.values\n",
    "# Set the chunk size (number of target variables per part)\n",
    "chunk_size = 40\n",
    "\n",
    "# Loop through target columns in chunks\n",
    "for chunk_start in range(200, 241, chunk_size):\n",
    "    # Get the current chunk of target columns\n",
    "    chunk_end = min(chunk_start + chunk_size, 241)\n",
    "    target_chunk = data_target.columns[chunk_start:chunk_end]\n",
    "    \n",
    "    # Initialize list to store results for the current chunk\n",
    "    chunk_results = []\n",
    "\n",
    "    # Open a file to write classification reports for the current chunk\n",
    "    report_file_path = f\"/home/qiuaodon/Desktop/CRC_image/Best_100_features_XGboost_90percents/Classification_Reports_100features_XGB_part_{chunk_start}_{chunk_end}.txt\"\n",
    "    with open(report_file_path, \"w\") as report_file:\n",
    "        # Loop through each target column in the current chunk\n",
    "        for target_col in target_chunk:\n",
    "            # Extract the target column for the current category\n",
    "            Y = data_target_train[target_col].values\n",
    "\n",
    "            # Encode the labels if necessary\n",
    "            label_encoder = LabelEncoder()\n",
    "            Y = label_encoder.fit_transform(Y)\n",
    "            \n",
    "            # Fit XGBoost to calculate feature importance\n",
    "            xgb_clf.fit(X, Y)\n",
    "\n",
    "            # Get feature importances and select the top 100 indices\n",
    "            importances = xgb_clf.feature_importances_\n",
    "            top_100_indices = np.argsort(importances)[-100:]\n",
    "\n",
    "            # Select top 100 features\n",
    "            X_selected = X[:, top_100_indices]\n",
    "            X_test_unseen_selected = X_test_unseen[:, top_100_indices]\n",
    "\n",
    "            # Split the data into training and testing sets\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "                X_selected, Y, test_size=0.2, random_state=42, stratify=Y\n",
    "            )\n",
    "            \n",
    "            # Define the hyperparameter distribution for RandomizedSearchCV\n",
    "            param_dist = {\n",
    "                'max_depth': randint(6, 13),\n",
    "                'min_child_weight': randint(1, 10),\n",
    "                'subsample': uniform(0.9, 0.1),\n",
    "                'colsample_bytree': uniform(0.9, 0.1),\n",
    "                'learning_rate': uniform(0.01, 0.05),\n",
    "                'n_estimators': randint(1000, 1500),\n",
    "                'gamma': uniform(2, 3),\n",
    "            }\n",
    "            \n",
    "            # Perform Randomized Search with cross-validation\n",
    "            random_search = RandomizedSearchCV(\n",
    "                estimator=xgb_clf,\n",
    "                param_distributions=param_dist,\n",
    "                n_iter=160, \n",
    "                cv=5,\n",
    "                scoring='f1_weighted',\n",
    "                n_jobs=-1,\n",
    "                verbose=1,\n",
    "                random_state=42\n",
    "            )\n",
    "            random_search.fit(X_train, Y_train)\n",
    "            \n",
    "            # Get the best model from Randomized Search\n",
    "            best_xgb = random_search.best_estimator_\n",
    "            best_params = random_search.best_params_\n",
    "            \n",
    "            # Evaluate on the training set\n",
    "            Y_train_pred = best_xgb.predict(X_train)\n",
    "            train_report_dict = classification_report(Y_train, Y_train_pred, output_dict=True)\n",
    "            train_report = classification_report(Y_train, Y_train_pred)\n",
    "            \n",
    "            # Evaluate on the test set\n",
    "            Y_test_pred = best_xgb.predict(X_test)\n",
    "            test_report_dict = classification_report(Y_test, Y_test_pred, output_dict=True)\n",
    "            test_report = classification_report(Y_test, Y_test_pred)\n",
    "            \n",
    "            # Evaluate on the unseen test data\n",
    "            Y_test_unseen_col = data_target_unseen[target_col].values\n",
    "            Y_test_unseen_col = label_encoder.transform(Y_test_unseen_col)\n",
    "            Y_test_unseen_pred = best_xgb.predict(X_test_unseen_selected)\n",
    "            unseen_test_report_dict = classification_report(Y_test_unseen_col, Y_test_unseen_pred, output_dict=True)\n",
    "            unseen_test_report = classification_report(Y_test_unseen_col, Y_test_unseen_pred)\n",
    "\n",
    "            # Write classification reports to the file\n",
    "            report_file.write(f\"Classification Report for {target_col} (Train Set):\\n\")\n",
    "            report_file.write(train_report)\n",
    "            report_file.write(\"\\n\")\n",
    "            report_file.write(f\"Classification Report for {target_col} (Test Set):\\n\")\n",
    "            report_file.write(test_report)\n",
    "            report_file.write(\"\\n\")\n",
    "            report_file.write(f\"Classification Report for {target_col} (Unseen Test Set):\\n\")\n",
    "            report_file.write(unseen_test_report)\n",
    "            report_file.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\")\n",
    "            \n",
    "            # Calculate overall test metrics\n",
    "            test_precision = precision_score(Y_test, Y_test_pred, average='weighted')\n",
    "            test_recall = recall_score(Y_test, Y_test_pred, average='weighted')\n",
    "            test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "            \n",
    "            # Calculate overall unseen test metrics\n",
    "            unseen_test_precision = precision_score(Y_test_unseen_col, Y_test_unseen_pred, average='weighted')\n",
    "            unseen_test_recall = recall_score(Y_test_unseen_col, Y_test_unseen_pred, average='weighted')\n",
    "            unseen_test_accuracy = accuracy_score(Y_test_unseen_col, Y_test_unseen_pred)\n",
    "\n",
    "            # Extract test Class 1 metrics\n",
    "            class_1_metrics = test_report_dict.get('1', {\"precision\": None, \"recall\": None, \"f1-score\": None})\n",
    "\n",
    "            # Extract unseen test Class 1 metrics\n",
    "            class_1_unseen_metrics = unseen_test_report_dict.get('1', {\"precision\": None, \"recall\": None, \"f1-score\": None})\n",
    "\n",
    "            # Append results to chunk_results\n",
    "            chunk_results.append({\n",
    "                \"Target Variable\": target_col,\n",
    "                \"Test Precision\": test_precision,\n",
    "                \"Test Recall\": test_recall,\n",
    "                \"Test Accuracy\": test_accuracy,\n",
    "                \"Class 1 Precision (Test)\": class_1_metrics[\"precision\"],\n",
    "                \"Class 1 Recall (Test)\": class_1_metrics[\"recall\"],\n",
    "                \"Class 1 F1-Score (Test)\": class_1_metrics[\"f1-score\"],\n",
    "                \"Unseen Test Precision\": unseen_test_precision,\n",
    "                \"Unseen Test Recall\": unseen_test_recall,\n",
    "                \"Unseen Test Accuracy\": unseen_test_accuracy,\n",
    "                \"Class 1 Precision (Unseen Test)\": class_1_unseen_metrics[\"precision\"],\n",
    "                \"Class 1 Recall (Unseen Test)\": class_1_unseen_metrics[\"recall\"],\n",
    "                \"Class 1 F1-Score (Unseen Test)\": class_1_unseen_metrics[\"f1-score\"],\n",
    "                \"Best Hyperparameters\": best_params\n",
    "            })\n",
    "    \n",
    "    # Save the results for the current chunk to an Excel file\n",
    "    results_df = pd.DataFrame(chunk_results)\n",
    "    results_df.to_excel(\n",
    "        f\"/home/qiuaodon/Desktop/CRC_image/Best_100_features_XGboost_90percents/Precision_Recall_Accuracy_100features_XGB_part_{chunk_start}_{chunk_end}.xlsx\",\n",
    "        index=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (407, 768)\n",
      "Length of Y: 449\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Length of Y: {len(Y)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Variable</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Class 1 Precision (Test)</th>\n",
       "      <th>Class 1 Recall (Test)</th>\n",
       "      <th>Class 1 F1-Score (Test)</th>\n",
       "      <th>Unseen Test Precision</th>\n",
       "      <th>Unseen Test Recall</th>\n",
       "      <th>Unseen Test Accuracy</th>\n",
       "      <th>Class 1 Precision (Unseen Test)</th>\n",
       "      <th>Class 1 Recall (Unseen Test)</th>\n",
       "      <th>Class 1 F1-Score (Unseen Test)</th>\n",
       "      <th>Best Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category_b_3</td>\n",
       "      <td>0.513086</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.397756</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>{'colsample_bytree': 0.940895294441427, 'gamma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category_b_4</td>\n",
       "      <td>0.474930</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>{'colsample_bytree': 0.9922499381177297, 'gamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category_b_5</td>\n",
       "      <td>0.390111</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.357937</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>{'colsample_bytree': 0.9936729988736734, 'gamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category_b_6</td>\n",
       "      <td>0.434490</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.304762</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'colsample_bytree': 0.9790175540531206, 'gamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category_b_7</td>\n",
       "      <td>0.531728</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.373152</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>{'colsample_bytree': 0.9015456616528867, 'gamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>category_tnk_57</td>\n",
       "      <td>0.354274</td>\n",
       "      <td>0.353659</td>\n",
       "      <td>0.353659</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>0.479252</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>{'colsample_bytree': 0.9380890856631021, 'gamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>category_tnk_66</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.530423</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>{'colsample_bytree': 0.9663501769108056, 'gamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>category_tnk_67</td>\n",
       "      <td>0.424082</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.232426</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'colsample_bytree': 0.9929375989127586, 'gamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>category_b_1</td>\n",
       "      <td>0.451296</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.353619</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>{'colsample_bytree': 0.9737501248109749, 'gamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>category_b_2</td>\n",
       "      <td>0.474057</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.369505</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>{'colsample_bytree': 0.9511342398860938, 'gamm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target Variable  Test Precision  Test Recall  Test Accuracy  \\\n",
       "0       category_b_3        0.513086     0.512195       0.512195   \n",
       "1       category_b_4        0.474930     0.475610       0.475610   \n",
       "2       category_b_5        0.390111     0.390244       0.390244   \n",
       "3       category_b_6        0.434490     0.439024       0.439024   \n",
       "4       category_b_7        0.531728     0.524390       0.524390   \n",
       "..               ...             ...          ...            ...   \n",
       "236  category_tnk_57        0.354274     0.353659       0.353659   \n",
       "237  category_tnk_66        0.524390     0.524390       0.524390   \n",
       "238  category_tnk_67        0.424082     0.426829       0.426829   \n",
       "239     category_b_1        0.451296     0.463415       0.463415   \n",
       "240     category_b_2        0.474057     0.475610       0.475610   \n",
       "\n",
       "     Class 1 Precision (Test)  Class 1 Recall (Test)  Class 1 F1-Score (Test)  \\\n",
       "0                    0.448276               0.464286                 0.456140   \n",
       "1                    0.461538               0.444444                 0.452830   \n",
       "2                    0.416667               0.357143                 0.384615   \n",
       "3                    0.421053               0.285714                 0.340426   \n",
       "4                    0.526316               0.357143                 0.425532   \n",
       "..                        ...                    ...                      ...   \n",
       "236                  0.343750               0.407407                 0.372881   \n",
       "237                  0.500000               0.500000                 0.500000   \n",
       "238                  0.321429               0.321429                 0.321429   \n",
       "239                  0.347826               0.275862                 0.307692   \n",
       "240                  0.486486               0.642857                 0.553846   \n",
       "\n",
       "     Unseen Test Precision  Unseen Test Recall  Unseen Test Accuracy  \\\n",
       "0                 0.397756            0.357143              0.357143   \n",
       "1                 0.379630            0.380952              0.380952   \n",
       "2                 0.357937            0.357143              0.357143   \n",
       "3                 0.304762            0.285714              0.285714   \n",
       "4                 0.373152            0.380952              0.380952   \n",
       "..                     ...                 ...                   ...   \n",
       "236               0.479252            0.452381              0.452381   \n",
       "237               0.530423            0.404762              0.404762   \n",
       "238               0.232426            0.238095              0.238095   \n",
       "239               0.353619            0.285714              0.285714   \n",
       "240               0.369505            0.333333              0.333333   \n",
       "\n",
       "     Class 1 Precision (Unseen Test)  Class 1 Recall (Unseen Test)  \\\n",
       "0                           0.315789                      0.666667   \n",
       "1                           0.375000                      0.214286   \n",
       "2                           0.111111                      0.100000   \n",
       "3                           0.000000                      0.000000   \n",
       "4                           0.222222                      0.181818   \n",
       "..                               ...                           ...   \n",
       "236                         0.461538                      0.461538   \n",
       "237                         0.222222                      0.500000   \n",
       "238                         0.000000                      0.000000   \n",
       "239                         0.066667                      0.125000   \n",
       "240                         0.076923                      0.111111   \n",
       "\n",
       "     Class 1 F1-Score (Unseen Test)  \\\n",
       "0                          0.428571   \n",
       "1                          0.272727   \n",
       "2                          0.105263   \n",
       "3                          0.000000   \n",
       "4                          0.200000   \n",
       "..                              ...   \n",
       "236                        0.461538   \n",
       "237                        0.307692   \n",
       "238                        0.000000   \n",
       "239                        0.086957   \n",
       "240                        0.090909   \n",
       "\n",
       "                                  Best Hyperparameters  \n",
       "0    {'colsample_bytree': 0.940895294441427, 'gamma...  \n",
       "1    {'colsample_bytree': 0.9922499381177297, 'gamm...  \n",
       "2    {'colsample_bytree': 0.9936729988736734, 'gamm...  \n",
       "3    {'colsample_bytree': 0.9790175540531206, 'gamm...  \n",
       "4    {'colsample_bytree': 0.9015456616528867, 'gamm...  \n",
       "..                                                 ...  \n",
       "236  {'colsample_bytree': 0.9380890856631021, 'gamm...  \n",
       "237  {'colsample_bytree': 0.9663501769108056, 'gamm...  \n",
       "238  {'colsample_bytree': 0.9929375989127586, 'gamm...  \n",
       "239  {'colsample_bytree': 0.9737501248109749, 'gamm...  \n",
       "240  {'colsample_bytree': 0.9511342398860938, 'gamm...  \n",
       "\n",
       "[241 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Specify the directory where your files are located\n",
    "file_path_pattern = '/home/qiuaodon/Desktop/CRC_image/Best_100_features_XGboost_90percents/Precision_Recall_Accuracy_100features_XGB_part_*.xlsx'\n",
    "\n",
    "# Use glob to find all matching files\n",
    "all_files = glob.glob(file_path_pattern)\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Loop through each file and append its DataFrame to the list\n",
    "for file in all_files:\n",
    "    df = pd.read_excel(file)\n",
    "    data_frames.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new Excel file\n",
    "combined_df.to_excel('/home/qiuaodon/Desktop/CRC_image/Best_100_features_XGboost_90percents/Combined_Precision_Recall_Accuracy_100features_XGB_241_targets.xlsx', index=False)\n",
    "combined_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
