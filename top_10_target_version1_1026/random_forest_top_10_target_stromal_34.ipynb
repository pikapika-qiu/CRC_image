{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Desktop/project_data_new/embedding_768_TCGA_COAD.csv')\n",
    "data.index = data['PatientID']\n",
    "# drop last 2 columns\n",
    "data = data.drop(data.columns[-2:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target = pd.read_csv('~/Desktop/project_data_new/target_768_avg_expanded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target.index = data_target['Unnamed: 0']\n",
    "data_target = data_target.drop(['Unnamed: 0'], axis = 1)\n",
    "# only keep the columns with category in the name\n",
    "data_target = data_target.loc[:, data_target.columns.str.contains('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data.index.isin(data_target.index)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.values\n",
    "# Extract the target column for category_b_12\n",
    "Y = data_target['category_stromal_34'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rfe = RFE(rf, n_features_to_select=100)  # Choose top 100 features\n",
    "X = rfe.fit_transform(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the selected features to csv \n",
    "np.savetxt(\"/home/qiuaodon/Desktop/CRC_image/Best_features_REF/Top_100_features_REF_stromal_34.csv\", X, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the selected features from csv\n",
    "X = np.loadtxt(\"/home/qiuaodon/Desktop/CRC_image/Best_features_RandomForest_results/Top_100_features_REF_stromal_34.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 359 folds for each of 60 candidates, totalling 21540 fits\n",
      "Best Hyperparameters: {'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 11, 'n_estimators': 163}\n",
      "Cross-validation F1 scores on training set: [0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      " 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "Average cross-validation F1 score on training set: 0.5459610027855153\n",
      "Classification Report for stromal_34 (Train Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       122\n",
      "           0       0.98      1.00      0.99       124\n",
      "           1       1.00      0.98      0.99       113\n",
      "\n",
      "    accuracy                           0.99       359\n",
      "   macro avg       0.99      0.99      0.99       359\n",
      "weighted avg       0.99      0.99      0.99       359\n",
      "\n",
      "Classification Report for stromal_34 (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.71      0.65        28\n",
      "           0       0.58      0.60      0.59        25\n",
      "           1       0.80      0.65      0.72        37\n",
      "\n",
      "    accuracy                           0.66        90\n",
      "   macro avg       0.66      0.65      0.65        90\n",
      "weighted avg       0.67      0.66      0.66        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# leave one out cross validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, LeaveOneOut\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Extract the target column for category_stromal_34\n",
    "Y = data_target['category_stromal_34'].values\n",
    "\n",
    "# Split the data into training and testing sets (20% test set)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter distribution (use distributions for random search)\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 200),            # Fewer trees may generalize better\n",
    "    'max_depth': randint(20, 40),                 # Lower depth can prevent overfitting\n",
    "    'min_samples_split': randint(10, 20),         # Increase split to limit tree growth\n",
    "    'min_samples_leaf': randint(1, 5),            # Require more samples per leaf\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Perform Randomized Search with Leave-One-Out cross-validation\n",
    "loo = LeaveOneOut()\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=60,\n",
    "    cv=loo,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model from Randomized Search\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Cross-validation on the training set with the best model using LOOCV\n",
    "cv_scores = cross_val_score(best_rf, X_train, Y_train, cv=loo, scoring='f1_weighted', n_jobs=-1)\n",
    "print(\"Cross-validation F1 scores on training set:\", cv_scores)\n",
    "print(\"Average cross-validation F1 score on training set:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the training data for the final evaluation on test and train sets\n",
    "best_rf.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_rf.predict(X_train)\n",
    "print(\"Classification Report for stromal_34 (Train Set):\")\n",
    "print(classification_report(Y_train, Y_train_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_test_pred = best_rf.predict(X_test)\n",
    "print(\"Classification Report for stromal_34 (Test Set):\")\n",
    "print(classification_report(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best Hyperparameters: {'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 11, 'n_estimators': 163}\n",
      "Cross-validation F1 scores on training set: [0.57375959 0.54551249 0.5131099  0.50294538 0.42389621]\n",
      "Average cross-validation F1 score on training set: 0.5118447140391206\n",
      "Classification Report for stromal_34 (Train Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       122\n",
      "           0       0.98      1.00      0.99       124\n",
      "           1       1.00      0.98      0.99       113\n",
      "\n",
      "    accuracy                           0.99       359\n",
      "   macro avg       0.99      0.99      0.99       359\n",
      "weighted avg       0.99      0.99      0.99       359\n",
      "\n",
      "Classification Report for stromal_34 (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.71      0.65        28\n",
      "           0       0.58      0.60      0.59        25\n",
      "           1       0.80      0.65      0.72        37\n",
      "\n",
      "    accuracy                           0.66        90\n",
      "   macro avg       0.66      0.65      0.65        90\n",
      "weighted avg       0.67      0.66      0.66        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "# Extract the target column for category_b_12\n",
    "Y = data_target['category_stromal_34'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.05, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter distribution (use distributions for random search)\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 200),            # Fewer trees may generalize better\n",
    "    'max_depth': randint(20, 40),                 # Lower depth can prevent overfitting\n",
    "    'min_samples_split': randint(10, 20),         # Increase split to limit tree growth\n",
    "    'min_samples_leaf': randint(1, 5),            # Require more samples per leaf\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "# Perform Randomized Search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=60, \n",
    "                                   cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model from Randomized Search\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Cross-validation on the training set with the best model\n",
    "cv_scores = cross_val_score(best_rf, X_train, Y_train, cv=5, scoring='f1_weighted')\n",
    "print(\"Cross-validation F1 scores on training set:\", cv_scores)\n",
    "print(\"Average cross-validation F1 score on training set:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the training data for the final evaluation on test and train sets\n",
    "best_rf.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_rf.predict(X_train)\n",
    "print(\"Classification Report for stromal_34 (Train Set):\")\n",
    "print(classification_report(Y_train, Y_train_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_test_pred = best_rf.predict(X_test)\n",
    "print(\"Classification Report for stromal_34 (Test Set):\")\n",
    "print(classification_report(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = data.values\n",
    "rf = RandomForestClassifier()\n",
    "rfe = RFE(rf, n_features_to_select=150)  # Choose top 150 features\n",
    "X = rfe.fit_transform(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save X as Top_100_features_REF\n",
    "np.savetxt(\"Top_150_features_REF_stromal_34.csv\", X, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Hyperparameters: {'max_depth': 27, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 14, 'n_estimators': 196}\n",
      "Cross-validation F1 scores on training set: [0.54395277 0.54526985 0.47210822 0.48580817 0.46648453]\n",
      "Average cross-validation F1 score on training set: 0.502724707792862\n",
      "Classification Report for category_stromal_34 (Train Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       122\n",
      "           0       0.98      1.00      0.99       124\n",
      "           1       1.00      0.98      0.99       113\n",
      "\n",
      "    accuracy                           0.99       359\n",
      "   macro avg       0.99      0.99      0.99       359\n",
      "weighted avg       0.99      0.99      0.99       359\n",
      "\n",
      "Classification Report for category_stromal_34 (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.64      0.59        28\n",
      "           0       0.52      0.56      0.54        25\n",
      "           1       0.70      0.57      0.63        37\n",
      "\n",
      "    accuracy                           0.59        90\n",
      "   macro avg       0.59      0.59      0.59        90\n",
      "weighted avg       0.60      0.59      0.59        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "\n",
    "# X = data.values\n",
    "\n",
    "# Extract the target column for category_b_12\n",
    "Y = data_target['category_stromal_34'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter distribution (use distributions for random search)\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 200),            # Fewer trees may generalize better\n",
    "    'max_depth': randint(20, 40),                 # Lower depth can prevent overfitting\n",
    "    'min_samples_split': randint(10, 20),         # Increase split to limit tree growth\n",
    "    'min_samples_leaf': randint(1, 5),            # Require more samples per leaf\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "# Perform Randomized Search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=50, \n",
    "                                   cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model from Randomized Search\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Cross-validation on the training set with the best model\n",
    "cv_scores = cross_val_score(best_rf, X_train, Y_train, cv=5, scoring='f1_weighted')\n",
    "print(\"Cross-validation F1 scores on training set:\", cv_scores)\n",
    "print(\"Average cross-validation F1 score on training set:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the training data for the final evaluation on test and train sets\n",
    "best_rf.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_rf.predict(X_train)\n",
    "print(\"Classification Report for category_stromal_34 (Train Set):\")\n",
    "print(classification_report(Y_train, Y_train_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_test_pred = best_rf.predict(X_test)\n",
    "print(\"Classification Report for category_stromal_34 (Test Set):\")\n",
    "print(classification_report(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('Top_150_features_REF.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = data.values\n",
    "rf = RandomForestClassifier()\n",
    "rfe = RFE(rf, n_features_to_select=50)  # Choose top 100 features\n",
    "X = rfe.fit_transform(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save X as Top_100_features_REF\n",
    "np.savetxt(\"Top_50_features_REF_stromal_34.csv\", X, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 14, 'max_features': 'sqrt', 'min_samples_leaf': 13, 'min_samples_split': 21, 'n_estimators': 132}\n",
      "Cross-validation F1 scores on training set: [0.54241049 0.55413355 0.45965992 0.54186761 0.45534618]\n",
      "Average cross-validation F1 score on training set: 0.510683551468428\n",
      "Classification Report with 50 features (Train Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.74      0.75       122\n",
      "           0       0.67      0.74      0.70       124\n",
      "           1       0.72      0.66      0.69       113\n",
      "\n",
      "    accuracy                           0.72       359\n",
      "   macro avg       0.72      0.71      0.72       359\n",
      "weighted avg       0.72      0.72      0.72       359\n",
      "\n",
      "Classification Report 50 features (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.61      0.58        28\n",
      "           0       0.58      0.60      0.59        25\n",
      "           1       0.70      0.62      0.66        37\n",
      "\n",
      "    accuracy                           0.61        90\n",
      "   macro avg       0.61      0.61      0.61        90\n",
      "weighted avg       0.62      0.61      0.61        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "\n",
    "# X = data.values\n",
    "X \n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter distribution (use distributions for random search)\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 150),            # Fewer trees may generalize better\n",
    "    'max_depth': randint(8, 15),                 # Lower depth can prevent overfitting\n",
    "    'min_samples_split': randint(20, 25),         # Increase split to limit tree growth\n",
    "    'min_samples_leaf': randint(10, 15),            # Require more samples per leaf\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "# Perform Randomized Search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=80, \n",
    "                                   cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model from Randomized Search\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Cross-validation on the training set with the best model\n",
    "cv_scores = cross_val_score(best_rf, X_train, Y_train, cv=5, scoring='f1_weighted')\n",
    "print(\"Cross-validation F1 scores on training set:\", cv_scores)\n",
    "print(\"Average cross-validation F1 score on training set:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the training data for the final evaluation on test and train sets\n",
    "best_rf.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_rf.predict(X_train)\n",
    "print(\"Classification Report with 50 features (Train Set):\")\n",
    "print(classification_report(Y_train, Y_train_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_test_pred = best_rf.predict(X_test)\n",
    "print(\"Classification Report 50 features (Test Set):\")\n",
    "print(classification_report(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6336 candidates, totalling 31680 fits\n",
      "Best Hyperparameters: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 25, 'n_estimators': 140}\n",
      "Cross-validation F1 scores on training set: [0.54265873 0.5317864  0.5014315  0.54341182 0.45401102]\n",
      "Average cross-validation F1 score on training set: 0.5146598945070727\n",
      "Classification Report with 50 features (Train Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.76      0.78       122\n",
      "           0       0.71      0.74      0.73       124\n",
      "           1       0.75      0.75      0.75       113\n",
      "\n",
      "    accuracy                           0.75       359\n",
      "   macro avg       0.75      0.75      0.75       359\n",
      "weighted avg       0.75      0.75      0.75       359\n",
      "\n",
      "Classification Report 50 features (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.61      0.60        28\n",
      "           0       0.52      0.52      0.52        25\n",
      "           1       0.67      0.65      0.66        37\n",
      "\n",
      "    accuracy                           0.60        90\n",
      "   macro avg       0.59      0.59      0.59        90\n",
      "weighted avg       0.60      0.60      0.60        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X and Y_category_b_12 are already defined\n",
    "# X = data.values\n",
    "# Y_category_b_12 = data_target['category_b_12'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid (specific values for each hyperparameter)\n",
    "param_grid = {\n",
    "    'n_estimators': list(range(120, 141, 2)),        # Every integer between 100 and 150 with step 10\n",
    "    'max_depth': list(range(8, 16)),                  # Every integer between 8 and 15\n",
    "    'min_samples_split': list(range(20, 26)),         # Every integer between 20 and 25\n",
    "    'min_samples_leaf': list(range(10, 16)),          # Every integer between 10 and 15\n",
    "    'max_features': ['sqrt', 'log2']                  # Options for max features\n",
    "}\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model from Grid Search\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Cross-validation on the training set with the best model\n",
    "cv_scores = cross_val_score(best_rf, X_train, Y_train, cv=5, scoring='f1_weighted')\n",
    "print(\"Cross-validation F1 scores on training set:\", cv_scores)\n",
    "print(\"Average cross-validation F1 score on training set:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the training data for the final evaluation on test and train sets\n",
    "best_rf.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_rf.predict(X_train)\n",
    "print(\"Classification Report with 50 features (Train Set):\")\n",
    "print(classification_report(Y_train, Y_train_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_test_pred = best_rf.predict(X_test)\n",
    "print(\"Classification Report 50 features (Test Set):\")\n",
    "print(classification_report(Y_test, Y_test_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
