{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Desktop/project_data_new/embedding_768_TCGA_COAD.csv')\n",
    "data.index = data['PatientID']\n",
    "# drop last 2 columns\n",
    "data = data.drop(data.columns[-2:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target = pd.read_csv('~/Desktop/project_data_new/target_768_avg_expanded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target.index = data_target['Unnamed: 0']\n",
    "data_target = data_target.drop(['Unnamed: 0'], axis = 1)\n",
    "# only keep the columns with category in the name\n",
    "data_target = data_target.loc[:, data_target.columns.str.contains('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data.index.isin(data_target.index)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.values\n",
    "# Extract the target column for category_b_12\n",
    "Y = data_target['category_stromal_62'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rfe = RFE(rf, n_features_to_select=100)  # Choose top 100 features\n",
    "X = rfe.fit_transform(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the selected features to csv \n",
    "np.savetxt(\"./Top_100_features_REF_stromal_62.csv\", X, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best Hyperparameters: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 119}\n",
      "Cross-validation F1 scores on training set: [0.57037037 0.54711126 0.53826087 0.44280611 0.52648009]\n",
      "Average cross-validation F1 score on training set: 0.525005740393141\n",
      "Classification Report for stromal_62 (Train Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       121\n",
      "           0       0.98      1.00      0.99       120\n",
      "           1       1.00      0.97      0.99       118\n",
      "\n",
      "    accuracy                           0.99       359\n",
      "   macro avg       0.99      0.99      0.99       359\n",
      "weighted avg       0.99      0.99      0.99       359\n",
      "\n",
      "Classification Report for stromal_62 (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.62      0.60        29\n",
      "           0       0.56      0.52      0.54        29\n",
      "           1       0.69      0.69      0.69        32\n",
      "\n",
      "    accuracy                           0.61        90\n",
      "   macro avg       0.61      0.61      0.61        90\n",
      "weighted avg       0.61      0.61      0.61        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "# Extract the target column for category_b_12\n",
    "Y = data_target['category_stromal_62'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter distribution (use distributions for random search)\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 200),            # Fewer trees may generalize better\n",
    "    'max_depth': randint(10, 20),                 # Lower depth can prevent overfitting\n",
    "    'min_samples_split': randint(10, 20),         # Increase split to limit tree growth\n",
    "    'min_samples_leaf': randint(1, 5),            # Require more samples per leaf\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "# Perform Randomized Search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=60, \n",
    "                                   cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model from Randomized Search\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Cross-validation on the training set with the best model\n",
    "cv_scores = cross_val_score(best_rf, X_train, Y_train, cv=5, scoring='f1_weighted')\n",
    "print(\"Cross-validation F1 scores on training set:\", cv_scores)\n",
    "print(\"Average cross-validation F1 score on training set:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the training data for the final evaluation on test and train sets\n",
    "best_rf.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_rf.predict(X_train)\n",
    "print(\"Classification Report for stromal_62 (Train Set):\")\n",
    "print(classification_report(Y_train, Y_train_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_test_pred = best_rf.predict(X_test)\n",
    "print(\"Classification Report for stromal_62 (Test Set):\")\n",
    "print(classification_report(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = data.values\n",
    "rf = RandomForestClassifier()\n",
    "rfe = RFE(rf, n_features_to_select=150)  # Choose top 150 features\n",
    "X = rfe.fit_transform(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save X as Top_100_features_REF\n",
    "np.savetxt(\"Top_150_features_REF_stromal_62.csv\", X, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Hyperparameters: {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 172}\n",
      "Cross-validation F1 scores on training set: [0.56746032 0.55790186 0.50993514 0.47295516 0.56934437]\n",
      "Average cross-validation F1 score on training set: 0.5355193696052591\n",
      "Classification Report for category_stromal_62 (Train Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       121\n",
      "           0       0.98      1.00      0.99       120\n",
      "           1       1.00      0.98      0.99       118\n",
      "\n",
      "    accuracy                           0.99       359\n",
      "   macro avg       0.99      0.99      0.99       359\n",
      "weighted avg       0.99      0.99      0.99       359\n",
      "\n",
      "Classification Report for category_stromal_62 (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.62      0.60        29\n",
      "           0       0.64      0.55      0.59        29\n",
      "           1       0.65      0.69      0.67        32\n",
      "\n",
      "    accuracy                           0.62        90\n",
      "   macro avg       0.62      0.62      0.62        90\n",
      "weighted avg       0.62      0.62      0.62        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "\n",
    "# X = data.values\n",
    "\n",
    "# Extract the target column for category_b_12\n",
    "Y = data_target['category_stromal_62'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter distribution (use distributions for random search)\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 200),            # Fewer trees may generalize better\n",
    "    'max_depth': randint(10, 20),                 # Lower depth can prevent overfitting\n",
    "    'min_samples_split': randint(10, 20),         # Increase split to limit tree growth\n",
    "    'min_samples_leaf': randint(1, 5),            # Require more samples per leaf\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "# Perform Randomized Search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=50, \n",
    "                                   cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model from Randomized Search\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Cross-validation on the training set with the best model\n",
    "cv_scores = cross_val_score(best_rf, X_train, Y_train, cv=5, scoring='f1_weighted')\n",
    "print(\"Cross-validation F1 scores on training set:\", cv_scores)\n",
    "print(\"Average cross-validation F1 score on training set:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the training data for the final evaluation on test and train sets\n",
    "best_rf.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_rf.predict(X_train)\n",
    "print(\"Classification Report for category_stromal_62 (Train Set):\")\n",
    "print(classification_report(Y_train, Y_train_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_test_pred = best_rf.predict(X_test)\n",
    "print(\"Classification Report for category_stromal_62 (Test Set):\")\n",
    "print(classification_report(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('Top_150_features_REF.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = data.values\n",
    "rf = RandomForestClassifier()\n",
    "rfe = RFE(rf, n_features_to_select=50)  # Choose top 100 features\n",
    "X = rfe.fit_transform(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save X as Top_100_features_REF\n",
    "np.savetxt(\"Top_50_features_REF_stromal_62.csv\", X, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "Best Hyperparameters: {'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 13, 'min_samples_split': 23, 'n_estimators': 107}\n",
      "Cross-validation F1 scores on training set: [0.582638   0.57049383 0.52624113 0.52909878 0.54598368]\n",
      "Average cross-validation F1 score on training set: 0.5508910844891146\n",
      "Classification Report with 50 features (Train Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.74      0.76       121\n",
      "           0       0.67      0.66      0.66       120\n",
      "           1       0.70      0.75      0.72       118\n",
      "\n",
      "    accuracy                           0.72       359\n",
      "   macro avg       0.72      0.72      0.72       359\n",
      "weighted avg       0.72      0.72      0.72       359\n",
      "\n",
      "Classification Report 50 features (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.59      0.58        29\n",
      "           0       0.63      0.59      0.61        29\n",
      "           1       0.61      0.62      0.62        32\n",
      "\n",
      "    accuracy                           0.60        90\n",
      "   macro avg       0.60      0.60      0.60        90\n",
      "weighted avg       0.60      0.60      0.60        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter distribution (use distributions for random search)\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 150),            # Fewer trees may generalize better\n",
    "    'max_depth': randint(8, 15),                 # Lower depth can prevent overfitting\n",
    "    'min_samples_split': randint(20, 25),         # Increase split to limit tree growth\n",
    "    'min_samples_leaf': randint(10, 15),            # Require more samples per leaf\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "# Perform Randomized Search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=80, \n",
    "                                   cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model from Randomized Search\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Cross-validation on the training set with the best model\n",
    "cv_scores = cross_val_score(best_rf, X_train, Y_train, cv=5, scoring='f1_weighted')\n",
    "print(\"Cross-validation F1 scores on training set:\", cv_scores)\n",
    "print(\"Average cross-validation F1 score on training set:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the training data for the final evaluation on test and train sets\n",
    "best_rf.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_rf.predict(X_train)\n",
    "print(\"Classification Report with 50 features (Train Set):\")\n",
    "print(classification_report(Y_train, Y_train_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_test_pred = best_rf.predict(X_test)\n",
    "print(\"Classification Report 50 features (Test Set):\")\n",
    "print(classification_report(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6336 candidates, totalling 31680 fits\n",
      "Best Hyperparameters: {'max_depth': 8, 'max_features': 'log2', 'min_samples_leaf': 13, 'min_samples_split': 20, 'n_estimators': 122}\n",
      "Cross-validation F1 scores on training set: [0.5690247  0.57064813 0.50930472 0.54328309 0.5462198 ]\n",
      "Average cross-validation F1 score on training set: 0.5476960905156406\n",
      "Classification Report with 50 features (Train Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.75      0.76       121\n",
      "           0       0.66      0.64      0.65       120\n",
      "           1       0.71      0.75      0.73       118\n",
      "\n",
      "    accuracy                           0.71       359\n",
      "   macro avg       0.71      0.71      0.71       359\n",
      "weighted avg       0.71      0.71      0.71       359\n",
      "\n",
      "Classification Report 50 features (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.61      0.59      0.60        29\n",
      "           0       0.64      0.62      0.63        29\n",
      "           1       0.62      0.66      0.64        32\n",
      "\n",
      "    accuracy                           0.62        90\n",
      "   macro avg       0.62      0.62      0.62        90\n",
      "weighted avg       0.62      0.62      0.62        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X and Y_category_b_12 are already defined\n",
    "# X = data.values\n",
    "# Y_category_b_12 = data_target['category_b_12'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid (specific values for each hyperparameter)\n",
    "param_grid = {\n",
    "    'n_estimators': list(range(120, 141, 2)),        # Every integer between 100 and 150 with step 10\n",
    "    'max_depth': list(range(8, 16)),                  # Every integer between 8 and 15\n",
    "    'min_samples_split': list(range(20, 26)),         # Every integer between 20 and 25\n",
    "    'min_samples_leaf': list(range(10, 16)),          # Every integer between 10 and 15\n",
    "    'max_features': ['sqrt', 'log2']                  # Options for max features\n",
    "}\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best model from Grid Search\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Cross-validation on the training set with the best model\n",
    "cv_scores = cross_val_score(best_rf, X_train, Y_train, cv=5, scoring='f1_weighted')\n",
    "print(\"Cross-validation F1 scores on training set:\", cv_scores)\n",
    "print(\"Average cross-validation F1 score on training set:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the training data for the final evaluation on test and train sets\n",
    "best_rf.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "Y_train_pred = best_rf.predict(X_train)\n",
    "print(\"Classification Report with 50 features (Train Set):\")\n",
    "print(classification_report(Y_train, Y_train_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_test_pred = best_rf.predict(X_test)\n",
    "print(\"Classification Report 50 features (Test Set):\")\n",
    "print(classification_report(Y_test, Y_test_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
