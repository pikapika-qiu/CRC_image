{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in embedding_768_TCGA_COAD.csv\n",
    "data = pd.read_csv('/home/qiuaodon/Desktop/project_data_new/embedding_768_TCGA_COAD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (460, 770)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the last two columns\n",
    "# set the column patient_id as index\n",
    "data.index = data.iloc[:, -1]\n",
    "data = data.iloc[:, :-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop(index=0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "import random\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Transpose the data so that features are now samples\n",
    "data_T = data.T  # Assuming 'data' is a pandas DataFrame\n",
    "\n",
    "# Parameters\n",
    "num_clusters_range = range(2, 14)  # Testing cluster counts from 2 to 10\n",
    "n_resamples = 100  # Number of resampling iterations\n",
    "\n",
    "# Initialize variables\n",
    "num_features = data_T.shape[0]  # Number of features (now samples)\n",
    "feature_names = data_T.index     # Feature names\n",
    "consensus_matrices = {}          # To store consensus matrices for each cluster count\n",
    "\n",
    "# Perform consensus clustering on features\n",
    "for n_clusters in num_clusters_range:\n",
    "    print(f\"Processing {n_clusters} clusters...\")\n",
    "    temp_matrix = np.zeros((num_features, num_features))\n",
    "    \n",
    "    for _ in range(n_resamples):\n",
    "        # Randomly sample 80% of the patients (now features) without replacement\n",
    "        sample_indices = np.random.choice(data_T.columns, size=int(data_T.shape[1] * 0.8), replace=False)\n",
    "        sampled_data = data_T.loc[:, sample_indices]\n",
    "        \n",
    "        # Apply KMeans clustering to the features\n",
    "        kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=None)\n",
    "        labels = kmeans.fit_predict(sampled_data)\n",
    "        \n",
    "        # Update the co-occurrence matrix\n",
    "        for i in range(num_features):\n",
    "            for j in range(num_features):\n",
    "                if labels[i] == labels[j]:\n",
    "                    temp_matrix[i, j] += 1\n",
    "    \n",
    "    # Normalize the temporary matrix\n",
    "    temp_matrix /= n_resamples\n",
    "    # Store the consensus matrix for this cluster count\n",
    "    consensus_matrices[n_clusters] = temp_matrix\n",
    "\n",
    "    # Convert the consensus matrix to a distance matrix\n",
    "    distance_matrix = 1 - temp_matrix\n",
    "\n",
    "    # Perform hierarchical clustering\n",
    "    # Since distance_matrix is a square matrix, we need to convert it to a condensed distance matrix\n",
    "    condensed_distance = squareform(distance_matrix, checks=False)\n",
    "    linkage_matrix = linkage(condensed_distance, method='average')\n",
    "\n",
    "    # Assign clusters based on the linkage matrix\n",
    "    cluster_assignments = fcluster(linkage_matrix, n_clusters, criterion='maxclust')\n",
    "\n",
    "    # Create a DataFrame to save the assignments\n",
    "    assignments_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Cluster': cluster_assignments\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    #assignments_df.to_csv(f'cluster_assignments_{n_clusters}_clusters.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pac(consensus_matrix, lower_bound=0.1, upper_bound=0.9):\n",
    "    import numpy as np\n",
    "    consensus_values = consensus_matrix.flatten()\n",
    "    pac = np.mean((consensus_values > lower_bound) & (consensus_values < upper_bound))\n",
    "    return pac\n",
    "\n",
    "pac_scores = {}\n",
    "for n_clusters, consensus_matrix in consensus_matrices.items():\n",
    "    pac_score = calculate_pac(consensus_matrix)\n",
    "    pac_scores[n_clusters] = pac_score\n",
    "    print(f'PAC score for {n_clusters} clusters: {pac_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Function to plot consensus matrices for multiple cluster numbers\n",
    "def plot_consensus_matrices(consensus_matrices, cluster_range):\n",
    "    for n_clusters in cluster_range:\n",
    "        # Get the consensus matrix for the given number of clusters\n",
    "        consensus_matrix = consensus_matrices[n_clusters]\n",
    "\n",
    "        # Perform KMeans clustering on the consensus matrix\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(consensus_matrix)\n",
    "\n",
    "        # Reorder the consensus matrix and feature indices by the cluster labels\n",
    "        sorted_indices = np.argsort(cluster_labels)\n",
    "        sorted_matrix = consensus_matrix[sorted_indices, :][:, sorted_indices]\n",
    "        sorted_feature_indices = np.array(range(len(consensus_matrix)))[sorted_indices]  # Reorder feature indices\n",
    "\n",
    "        # Plot the reordered consensus matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(sorted_matrix, cmap='viridis', xticklabels=sorted_feature_indices, yticklabels=sorted_feature_indices)\n",
    "        plt.title(f'Consensus Matrix for {n_clusters} Clusters')\n",
    "        plt.show()\n",
    "\n",
    "# Define the range of cluster numbers you want to plot\n",
    "cluster_range = range(2, 14)\n",
    "\n",
    "# Plot consensus matrices for clusters 2 to 10\n",
    "plot_consensus_matrices(consensus_matrices, cluster_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def plot_elbow_method(data, cluster_range):\n",
    "    inertia = []\n",
    "    \n",
    "    # Compute inertia for different numbers of clusters\n",
    "    for n_clusters in cluster_range:\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        kmeans.fit(data)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "    \n",
    "    # Plot inertia vs. number of clusters\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(cluster_range, inertia, marker='o')\n",
    "    plt.title('Elbow Method for Optimal Clusters')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Inertia (Sum of Squared Distances)')\n",
    "    plt.xticks(cluster_range)\n",
    "    plt.show()\n",
    "\n",
    "# Define the range of cluster numbers to test\n",
    "cluster_range = range(2, 14)\n",
    "\n",
    "# Call the function using your data (assuming `data` is your dataset)\n",
    "plot_elbow_method(data, cluster_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def plot_silhouette_score(data, cluster_range):\n",
    "    silhouette_avg = []\n",
    "    \n",
    "    # Compute the silhouette score for different numbers of clusters\n",
    "    for n_clusters in cluster_range:\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(data)\n",
    "        silhouette_avg.append(silhouette_score(data, cluster_labels))\n",
    "    \n",
    "    # Plot silhouette score vs. number of clusters\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(cluster_range, silhouette_avg, marker='o')\n",
    "    plt.title('Silhouette Score for Optimal Clusters')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.xticks(cluster_range)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function using your data (assuming `data` is your dataset)\n",
    "plot_silhouette_score(data, cluster_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score\n",
    "\n",
    "def plot_calinski_harabasz(data, cluster_range):\n",
    "    ch_scores = []\n",
    "    \n",
    "    # Compute the Calinski-Harabasz index for different numbers of clusters\n",
    "    for n_clusters in cluster_range:\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(data)\n",
    "        ch_scores.append(calinski_harabasz_score(data, cluster_labels))\n",
    "    \n",
    "    # Plot the Calinski-Harabasz index vs. number of clusters\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(cluster_range, ch_scores, marker='o')\n",
    "    plt.title('Calinski-Harabasz Index for Optimal Clusters')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Calinski-Harabasz Index')\n",
    "    plt.xticks(cluster_range)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function using your data\n",
    "plot_calinski_harabasz(data, cluster_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def plot_bic_aic(data, cluster_range):\n",
    "    bic_scores = []\n",
    "    aic_scores = []\n",
    "    \n",
    "    # Compute BIC and AIC for different numbers of clusters using GMM\n",
    "    for n_clusters in cluster_range:\n",
    "        gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "        gmm.fit(data)\n",
    "        bic_scores.append(gmm.bic(data))\n",
    "        aic_scores.append(gmm.aic(data))\n",
    "    \n",
    "    # Plot BIC and AIC vs. number of clusters\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(cluster_range, bic_scores, marker='o', label='BIC')\n",
    "    plt.plot(cluster_range, aic_scores, marker='o', label='AIC')\n",
    "    plt.title('BIC/AIC for Optimal Clusters')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.xticks(cluster_range)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function using your data\n",
    "plot_bic_aic(data, cluster_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_pac(consensus_matrix, lower_bound=0.1, upper_bound=0.9):\n",
    "    \"\"\"\n",
    "    Calculate the Proportion of Ambiguous Clustering (PAC) score.\n",
    "\n",
    "    Parameters:\n",
    "    - consensus_matrix: The consensus matrix from consensus clustering.\n",
    "    - lower_bound: The lower threshold for ambiguity (default is 0.1).\n",
    "    - upper_bound: The upper threshold for ambiguity (default is 0.9).\n",
    "\n",
    "    Returns:\n",
    "    - pac_score: The PAC score, where a lower value indicates more stable clustering.\n",
    "    \"\"\"\n",
    "    # Flatten the consensus matrix into a 1D array of values\n",
    "    consensus_values = consensus_matrix.flatten()\n",
    "\n",
    "    # Count the proportion of values between lower_bound and upper_bound\n",
    "    ambiguous_proportion = np.mean((consensus_values > lower_bound) & (consensus_values < upper_bound))\n",
    "\n",
    "    return ambiguous_proportion\n",
    "\n",
    "def plot_pac_scores(consensus_matrices, cluster_range):\n",
    "    \"\"\"\n",
    "    Plot the PAC scores for different numbers of clusters.\n",
    "\n",
    "    Parameters:\n",
    "    - consensus_matrices: A dictionary of consensus matrices, where the key is the number of clusters.\n",
    "    - cluster_range: The range of cluster numbers to compute PAC scores for.\n",
    "    \"\"\"\n",
    "    pac_scores = []\n",
    "\n",
    "    # Calculate PAC scores for each cluster number\n",
    "    for n_clusters in cluster_range:\n",
    "        consensus_matrix = consensus_matrices[n_clusters]\n",
    "        pac_score = calculate_pac(consensus_matrix)\n",
    "        pac_scores.append(pac_score)\n",
    "        print(f'PAC score for {n_clusters} clusters: {pac_score}')\n",
    "\n",
    "    # Plot PAC scores\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(cluster_range, pac_scores, marker='o', linestyle='-', color='b')\n",
    "    plt.title('PAC Score for Different Number of Clusters')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('PAC Score')\n",
    "    plt.xticks(cluster_range)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `consensus_matrices` is a dictionary with cluster numbers as keys and consensus matrices as values\n",
    "cluster_range = range(2, 14)  # For clusters 2 through 10\n",
    "plot_pac_scores(consensus_matrices, cluster_range)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
